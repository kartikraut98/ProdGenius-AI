{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import uuid\n",
    "from urllib.parse import urlparse\n",
    "from pathlib import Path\n",
    "\n",
    "import pg8000\n",
    "import mlflow\n",
    "import dagshub\n",
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "from dotenv import load_dotenv\n",
    "from google.cloud.sql.connector import Connector, IPTypes\n",
    "from sqlalchemy import text\n",
    "from datasets import Dataset \n",
    "\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langfuse.callback import CallbackHandler\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.document_loaders import DataFrameLoader\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "from src.graph import create_graph\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "\n",
    "# Apply asyncio patch for compatibility\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_PARENT_DIR = \"evaluation/\"\n",
    "EVAL_TESTSET_DIR = f\"{EVAL_PARENT_DIR}/testset\"\n",
    "EVAL_RESULTS_DIR = f\"{EVAL_PARENT_DIR}/results\"\n",
    "EVAL_METRICS_DIR = f\"{EVAL_PARENT_DIR}/metrics\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory paths\n",
    "cache_dir = Path(\"cache\")\n",
    "faiss_dir = cache_dir / \"faiss\"\n",
    "meta_dir = cache_dir / \"meta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the API Keys\n",
    "os.environ['HF_TOKEN']=os.getenv(\"HF_TOKEN\")\n",
    "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ['GROQ_API_KEY']=os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "## Langfusea\n",
    "os.environ['LANGFUSE_PUBLIC_KEY']=os.getenv(\"LANGFUSE_PUBLIC_KEY\")\n",
    "os.environ['LANGFUSE_SECRET_KEY']=os.getenv(\"LANGFUSE_SECRET_KEY\")\n",
    "os.environ['LANGFUSE_HOST']=os.getenv(\"LANGFUSE_HOST\")\n",
    "\n",
    "## Postgres DB\n",
    "instance_connection_name = os.getenv(\"INSTANCE_CONNECTION_NAME\")\n",
    "db_user = os.getenv(\"DB_USER\")  \n",
    "db_pass = os.getenv(\"DB_PASS\")  \n",
    "db_name = os.getenv(\"DB_NAME\")  \n",
    "\n",
    "# MlFlow\n",
    "os.environ[\"MLFLOW_TRACKING_URI\"]=os.getenv(\"MLFLOW_TRACKING_URI\")\n",
    "os.environ[\"MLFLOW_TRACKING_USERNAME\"]=os.getenv(\"MLFLOW_TRACKING_USERNAME\")\n",
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"]=os.getenv(\"MLFLOW_TRACKING_PASSWORD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import RAG Test Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all Parquet files in the directory\n",
    "parquet_files = [f for f in os.listdir(EVAL_TESTSET_DIR) if f.endswith('.parquet')]\n",
    "\n",
    "with open('artifact/product_uuids.json', 'r') as json_file:\n",
    "    asin_uuid_map = json.load(json_file)\n",
    "\n",
    "# Convert UUID-ASIN dictionary to reverse lookup (UUID as key, ASIN as value)\n",
    "uuid_asin_map = {v: k for k, v in asin_uuid_map.items()}\n",
    "\n",
    "# Read and combine DataFrames\n",
    "def process_parquet(f):\n",
    "    df = pd.read_parquet(os.path.join(EVAL_TESTSET_DIR, f))\n",
    "    df['file_hash'] = f.split('.')[0]\n",
    "    df['parent_asin'] = df['file_hash'].map(uuid_asin_map)\n",
    "    return df\n",
    "\n",
    "dfs = [process_parquet(f) for f in parquet_files]\n",
    "test_df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>evolution_type</th>\n",
       "      <th>count</th>\n",
       "      <th>total</th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simple</td>\n",
       "      <td>55</td>\n",
       "      <td>83</td>\n",
       "      <td>66.265060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>reasoning</td>\n",
       "      <td>25</td>\n",
       "      <td>83</td>\n",
       "      <td>30.120482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>multi_context</td>\n",
       "      <td>3</td>\n",
       "      <td>83</td>\n",
       "      <td>3.614458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  evolution_type  count  total    percent\n",
       "0         simple     55     83  66.265060\n",
       "1      reasoning     25     83  30.120482\n",
       "2  multi_context      3     83   3.614458"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evolution_type Coverage - % of each type in test & in full\n",
    "def get_percent_coverage(df):\n",
    "    etype_count_df = pd.DataFrame(df['evolution_type'].value_counts()).reset_index()\n",
    "    etype_count_df['total'] = df.shape[0]\n",
    "    etype_count_df['percent'] = (100 * etype_count_df['count'])/etype_count_df['total']\n",
    "    return etype_count_df\n",
    "\n",
    "etype_count_df_test = get_percent_coverage(test_df)\n",
    "etype_count_df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_with_db() -> sqlalchemy.engine.base.Engine:\n",
    "    ip_type = IPTypes.PRIVATE if os.getenv(\"PRIVATE_IP\") else IPTypes.PUBLIC\n",
    "    connector = Connector()\n",
    "    def getconn() -> pg8000.dbapi.Connection:\n",
    "        conn: pg8000.dbapi.Connection = connector.connect(\n",
    "            instance_connection_name,\n",
    "            \"pg8000\",\n",
    "            user=db_user,\n",
    "            password=db_pass,\n",
    "            db=db_name,\n",
    "            ip_type=ip_type,\n",
    "        )\n",
    "        return conn\n",
    "    pool = sqlalchemy.create_engine(\n",
    "        \"postgresql+pg8000://\",\n",
    "        creator=getconn,\n",
    "    )\n",
    "    return pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = connect_with_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_product_data(asin: str):\n",
    "    with engine.begin() as connection:\n",
    "        try:\n",
    "            # Fetch reviews\n",
    "            review_query = text(f\"\"\"\n",
    "                SELECT parent_asin, asin, helpful_vote, timestamp, verified_purchase, title, text\n",
    "                FROM userreviews ur \n",
    "                WHERE ur.parent_asin = '{asin}';\n",
    "            \"\"\")\n",
    "            review_result = connection.execute(review_query)\n",
    "            review_df = pd.DataFrame(review_result.fetchall(), columns=review_result.keys())\n",
    "            \n",
    "            # Fetch metadata\n",
    "            meta_query = text(f\"\"\"\n",
    "                SELECT parent_asin, main_category, title, average_rating, rating_number, features, description, price, store, categories, details\n",
    "                FROM metadata md \n",
    "                WHERE md.parent_asin = '{asin}';\n",
    "            \"\"\")\n",
    "            meta_result = connection.execute(meta_query)\n",
    "            meta_df = pd.DataFrame(meta_result.fetchall(), columns=meta_result.keys())\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(\"Exception: {}\".format(e))\n",
    "\n",
    "    return review_df, meta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_store(review_df):\n",
    "    review_df = review_df[review_df['text'].notna()]\n",
    "    loader = DataFrameLoader(review_df)\n",
    "    review_docs = loader.load()\n",
    "\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "    vectordb = FAISS.from_documents(documents=review_docs, embedding=embeddings)\n",
    "    return vectordb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent: CompiledStateGraph = create_graph(isMemory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store_cache = []\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['answer'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-15 14:20:09,349: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:20:09,349: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "Response generated for query: What has been your experience with the Dirt Devil over the two years of use?\n",
      "Response generated for id: 0\n",
      "Response generated for query: What type of game is suitable for a family gathering?\n",
      "Response generated for id: 1\n",
      "[2024-11-15 14:20:21,286: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:20:21,287: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "Response generated for query: What type of game is mentioned as being similar to Gin Rummy?\n",
      "Response generated for id: 2\n",
      "Response generated for query: Any game recommendations for Gin Rummy fans?\n",
      "Response generated for id: 3\n",
      "Response generated for query: What type of game can be played with grand-kids that is easy for youngsters but challenging for all?\n",
      "Response generated for id: 4\n",
      "[2024-11-15 14:20:40,102: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:20:40,103: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:20:41,802: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:20:41,803: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:20:43,359: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:20:43,360: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:20:44,880: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:20:44,881: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:20:47,082: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 23.000000 seconds]\n",
      "Response generated for query: What are the characteristics of the materials used for memory work with ALZ patients?\n",
      "Response generated for id: 5\n",
      "[2024-11-15 14:21:16,734: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:21:16,735: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:21:18,531: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 26.000000 seconds]\n",
      "Response generated for query: Which game mixes color/shape matching with strategy, like sudoku and dominos?\n",
      "Response generated for id: 6\n",
      "[2024-11-15 14:21:48,659: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:21:48,659: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:21:50,367: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 4.000000 seconds]\n",
      "Response generated for query: What motivated the buyer to purchase the item despite its lower quality?\n",
      "Response generated for id: 7\n",
      "[2024-11-15 14:22:00,033: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:22:00,033: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:22:02,123: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 19.000000 seconds]\n",
      "Response generated for query: What makes playing with family enjoyable and easy to learn?\n",
      "Response generated for id: 8\n",
      "[2024-11-15 14:22:27,670: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 10.000000 seconds]\n",
      "Response generated for query: What are the key features and benefits of SET - The Family Card Game?\n",
      "Response generated for id: 9\n",
      "[2024-11-15 14:22:44,044: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 9.000000 seconds]\n",
      "Response generated for query: What card game features boost family fun and learning?\n",
      "Response generated for id: 10\n",
      "[2024-11-15 14:22:57,263: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:22:57,264: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:22:58,933: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 5.000000 seconds]\n",
      "Response generated for query: What was the customer's experience regarding the shipping speed of the item?\n",
      "Response generated for id: 11\n",
      "[2024-11-15 14:23:09,001: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 8.000000 seconds]\n",
      "Response generated for query: What type of toys are effective in keeping toddlers entertained?\n",
      "Response generated for id: 12\n",
      "[2024-11-15 14:23:23,089: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:23:23,089: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:23:24,623: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:23:24,624: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:23:26,175: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 24.000000 seconds]\n",
      "Response generated for query: What are the characteristics of a fast moving game like Skip-Bo?\n",
      "Response generated for id: 13\n",
      "[2024-11-15 14:23:55,165: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:23:55,166: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:24:00,518: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 5.000000 seconds]\n",
      "Response generated for query: What made you feel hooked on the game after your husband introduced it to you?\n",
      "Response generated for id: 14\n",
      "[2024-11-15 14:24:10,608: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:24:10,609: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:24:12,306: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 22.000000 seconds]\n",
      "Response generated for query: How do skill and strategy play into card sequencing and wild cards in SKIP BO?\n",
      "Response generated for id: 15\n",
      "[2024-11-15 14:24:41,521: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 8.000000 seconds]\n",
      "Response generated for query: What is the additional use of a placemat for dinner besides serving as a dining accessory?\n",
      "Response generated for id: 16\n",
      "[2024-11-15 14:24:54,897: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:24:54,898: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:24:56,690: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 15.000000 seconds]\n",
      "Response generated for query: What is the significance of building on a strong foundation when kids play with Legos?\n",
      "Response generated for id: 17\n",
      "[2024-11-15 14:25:17,510: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:25:17,510: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:25:18,891: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:25:18,892: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:25:20,181: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:25:20,182: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:25:21,618: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 31.000000 seconds]\n",
      "Response generated for query: How do LEGO and imagination boost kids' fine motor skills?\n",
      "Response generated for id: 18\n",
      "[2024-11-15 14:25:58,266: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:25:58,266: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:26:00,702: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 13.000000 seconds]\n",
      "Response generated for query: How does the speaker feel about their gaming skills?\n",
      "Response generated for id: 19\n",
      "[2024-11-15 14:26:21,658: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:26:21,658: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:26:24,223: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:26:24,223: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:26:28,275: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 29.000000 seconds]\n",
      "Response generated for query: What should you consider if you are looking for wooden or collectors editions of board games?\n",
      "Response generated for id: 20\n",
      "[2024-11-15 14:27:05,276: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 13.000000 seconds]\n",
      "Response generated for query: What are the mental perks of gaming with friends?\n",
      "Response generated for id: 21\n",
      "[2024-11-15 14:27:24,579: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:27:24,580: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:27:25,991: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:27:25,992: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:27:27,999: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 37.000000 seconds]\n",
      "Response generated for query: What makes Rummikub appealing to all ages, and what drawbacks do players note?\n",
      "Response generated for id: 22\n",
      "[2024-11-15 14:28:10,902: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:28:10,903: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:28:12,606: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 7.000000 seconds]\n",
      "Response generated for query: What was the condition of the item upon arrival?\n",
      "Response generated for id: 23\n",
      "[2024-11-15 14:28:25,121: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:28:25,122: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:28:26,903: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 20.000000 seconds]\n",
      "Response generated for query: What motivated the speaker to purchase games from childhood for their grandchildren?\n",
      "Response generated for id: 24\n",
      "[2024-11-15 14:28:52,713: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:28:52,714: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:28:54,055: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:28:54,055: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:28:55,494: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 24.000000 seconds]\n",
      "Response generated for query: Why are plastics favored for durability and usability?\n",
      "Response generated for id: 25\n",
      "[2024-11-15 14:29:25,566: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 11.000000 seconds]\n",
      "Response generated for query: What did you purchase for your 2 year old niece?\n",
      "Response generated for id: 26\n",
      "[2024-11-15 14:29:42,209: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:29:42,209: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:29:45,260: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:29:45,261: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:29:47,146: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 27.000000 seconds]\n",
      "Response generated for query: What are the benefits of using dot art for children's art projects?\n",
      "Response generated for id: 27\n",
      "[2024-11-15 14:30:21,547: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 9.000000 seconds]\n",
      "Response generated for query: What indoor summer fun keeps kids busy without the mess?\n",
      "Response generated for id: 28\n",
      "[2024-11-15 14:30:35,106: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 1.000000 seconds]\n",
      "Response generated for query: What role does game night play in bringing family and friends together?\n",
      "Response generated for id: 29\n",
      "[2024-11-15 14:30:41,978: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 8.000000 seconds]\n",
      "Response generated for query: What makes the Dixit games fun for all ages?\n",
      "Response generated for id: 30\n",
      "[2024-11-15 14:30:56,113: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:30:56,113: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:30:57,751: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 20.000000 seconds]\n",
      "Response generated for query: What gameplay and art elements attract all ages?\n",
      "Response generated for id: 31\n",
      "[2024-11-15 14:31:24,570: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:31:24,571: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:31:26,134: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 26.000000 seconds]\n",
      "Response generated for query: How do expansion packs boost player engagement and enjoyment across age groups?\n",
      "Response generated for id: 32\n",
      "[2024-11-15 14:31:57,526: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:31:57,527: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:31:59,120: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 6.000000 seconds]\n",
      "Response generated for query: What is the significance of fast delivery in the context of customer satisfaction?\n",
      "Response generated for id: 33\n",
      "[2024-11-15 14:32:10,722: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:32:10,722: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:32:12,322: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 20.000000 seconds]\n",
      "Response generated for query: What is the significance of large pieces in helping children learn how to play chess?\n",
      "Response generated for id: 34\n",
      "[2024-11-15 14:32:37,942: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:32:37,942: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:32:39,299: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:32:39,300: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:32:40,563: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:32:40,564: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:32:42,070: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 33.000000 seconds]\n",
      "Response generated for query: How do big pieces and moves help kids learn chess?\n",
      "Response generated for id: 35\n",
      "[2024-11-15 14:33:21,725: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:33:21,726: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:33:23,603: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:33:23,604: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:33:25,121: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 23.000000 seconds]\n",
      "Response generated for query: What has contributed to the consistent quality of Crayola crayons over the years?\n",
      "Response generated for id: 36\n",
      "[2024-11-15 14:33:53,979: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 10.000000 seconds]\n",
      "Response generated for query: What makes the 64 colors great for my little niece?\n",
      "Response generated for id: 37\n",
      "[2024-11-15 14:34:09,170: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:34:09,171: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:34:10,809: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 18.000000 seconds]\n",
      "Response generated for query: What advantages do Crayola crayons have for detailed art vs. other brands?\n",
      "Response generated for id: 38\n",
      "[2024-11-15 14:34:35,357: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:34:35,357: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:34:36,831: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:34:36,832: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:34:38,823: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 49.000000 seconds]\n",
      "Response generated for query: What role does problem-solving play in the enjoyment of the Rush Hour Traffic game?\n",
      "Response generated for id: 39\n",
      "[2024-11-15 14:35:35,108: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:35:35,108: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:35:36,417: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:35:36,417: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "Error invoking agent for Index: 40 - Error code: 413 - {'error': {'message': 'Request too large for model `llama-3.1-70b-versatile` in organization `org_01jcrm2x5rfjqbwamj32k2jcv2` on tokens per minute (TPM): Limit 6000, Requested 6278, please reduce your message size and try again. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "[2024-11-15 14:35:40,418: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:35:40,419: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:35:41,974: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 19.000000 seconds]\n",
      "Response generated for query: Any fun game ideas for boys 8-11 b-day?\n",
      "Response generated for id: 41\n",
      "[2024-11-15 14:36:07,173: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:36:07,174: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:36:08,769: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 23.000000 seconds]\n",
      "Response generated for query: What challenges does a short toddler face when using a push toy that is taller than expected?\n",
      "Response generated for id: 42\n",
      "[2024-11-15 14:36:38,334: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:36:38,335: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:36:39,549: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:36:39,550: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:36:46,469: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 27.000000 seconds]\n",
      "Response generated for query: What challenges does a short toddler face when using certain push toys?\n",
      "Response generated for id: 43\n",
      "[2024-11-15 14:37:22,207: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:37:22,208: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:37:23,773: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 30.000000 seconds]\n",
      "Response generated for query: What makes the shopping cart user-friendly for toddlers?\n",
      "Response generated for id: 44\n",
      "[2024-11-15 14:38:00,398: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:38:00,398: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:38:01,798: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 28.000000 seconds]\n",
      "Response generated for query: What benefits does a sturdy shopping cart offer for toddlers and preschoolers?\n",
      "Response generated for id: 45\n",
      "[2024-11-15 14:38:39,057: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:38:39,058: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:38:41,533: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 6.000000 seconds]\n",
      "Response generated for query: What is the significance of fast shipping in online transactions?\n",
      "Response generated for id: 46\n",
      "[2024-11-15 14:38:53,283: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:38:53,284: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:38:54,734: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:38:54,735: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:38:56,333: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 21.000000 seconds]\n",
      "Response generated for query: What makes the concept of an elf moving around the house a cute idea for children?\n",
      "Response generated for id: 47\n",
      "[2024-11-15 14:39:23,381: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:39:23,382: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:39:24,877: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 17.000000 seconds]\n",
      "Response generated for query: What makes The Elf on the Shelf a top Christmas seller?\n",
      "Response generated for id: 48\n",
      "[2024-11-15 14:39:48,880: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:39:48,881: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:39:50,329: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 28.000000 seconds]\n",
      "Response generated for query: What motivated the purchase from Amazon instead of Target?\n",
      "Response generated for id: 49\n",
      "[2024-11-15 14:40:24,206: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:40:24,207: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:40:25,817: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 26.000000 seconds]\n",
      "Response generated for query: What motivated the purchase from Amazon instead of Target?\n",
      "Response generated for id: 50\n",
      "[2024-11-15 14:40:57,445: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:40:57,446: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:40:59,502: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 17.000000 seconds]\n",
      "Response generated for query: How does a child's curiosity about the body aid learning and resilience?\n",
      "Response generated for id: 51\n",
      "[2024-11-15 14:41:22,264: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:41:22,264: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:41:23,736: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 11.000000 seconds]\n",
      "Response generated for query: What issue did the reviewer encounter with the book's binding?\n",
      "Response generated for id: 52\n",
      "[2024-11-15 14:41:40,488: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:41:40,489: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:41:41,766: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:41:41,767: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:41:43,482: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 25.000000 seconds]\n",
      "Response generated for query: What was the attempted solution for fixing the book's binding?\n",
      "Response generated for id: 53\n",
      "[2024-11-15 14:42:14,485: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:42:14,487: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:42:16,028: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:42:16,029: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:42:17,676: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 29.000000 seconds]\n",
      "Response generated for query: What effect does a sunny day have on the operation of the helicopter?\n",
      "Response generated for id: 54\n",
      "[2024-11-15 14:42:52,364: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:42:52,364: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:42:54,500: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 20.000000 seconds]\n",
      "Response generated for query: What makes the Syma S107 mini helicopter a great option in terms of entertainment value?\n",
      "Response generated for id: 55\n",
      "[2024-11-15 14:43:21,059: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:43:21,060: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:43:22,569: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:43:22,570: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:43:27,755: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 33.000000 seconds]\n",
      "Response generated for query: What makes the Syma S107 durable and user-friendly vs. other mini helis?\n",
      "Response generated for id: 56\n",
      "[2024-11-15 14:44:08,698: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 14.000000 seconds]\n",
      "Response generated for query: What are the benefits of play-based learning in teaching math to children?\n",
      "Response generated for id: 57\n",
      "[2024-11-15 14:44:29,152: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:44:29,152: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:44:31,054: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:44:31,054: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:44:32,797: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 24.000000 seconds]\n",
      "Response generated for query: What was the reason for the toy purchase despite concerns about quality?\n",
      "Response generated for id: 58\n",
      "[2024-11-15 14:45:03,013: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 11.000000 seconds]\n",
      "Response generated for query: What makes the cash register durable and educational for kids?\n",
      "Response generated for id: 59\n",
      "[2024-11-15 14:45:21,170: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:45:21,171: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:45:23,323: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 16.000000 seconds]\n",
      "Response generated for query: What features make the user-friendly controls appealing for babies?\n",
      "Response generated for id: 60\n",
      "[2024-11-15 14:45:44,121: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:45:44,122: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:45:45,881: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 9.000000 seconds]\n",
      "Response generated for query: What should one consider when looking at differing reviews for a product?\n",
      "Response generated for id: 61\n",
      "[2024-11-15 14:46:01,174: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 9.000000 seconds]\n",
      "Response generated for query: What features of the Munchkin Mozart Cube aid kids' music learning?\n",
      "Response generated for id: 62\n",
      "[2024-11-15 14:46:19,642: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:46:19,643: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:46:20,977: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:46:20,978: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:46:23,977: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 16.000000 seconds]\n",
      "Response generated for query: What was the occasion for the gift that was bought for the 2 year old?\n",
      "Response generated for id: 63\n",
      "[2024-11-15 14:46:44,287: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:46:44,288: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:46:45,692: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 7.000000 seconds]\n",
      "Response generated for query: What issue did the latch getting stuck cause when trying to use the box?\n",
      "Response generated for id: 64\n",
      "[2024-11-15 14:46:58,043: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:46:58,044: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:46:59,228: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:46:59,228: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:47:00,794: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 22.000000 seconds]\n",
      "Response generated for query: What interests could match my daughter's Curious George and keepsake toy?\n",
      "Response generated for id: 65\n",
      "[2024-11-15 14:47:30,033: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:47:30,034: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:47:31,771: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 23.000000 seconds]\n",
      "Response generated for query: What role does friendly interaction play in the enjoyment of the game?\n",
      "Response generated for id: 66\n",
      "[2024-11-15 14:48:01,182: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 9.000000 seconds]\n",
      "Response generated for query: Which game is fun for family word-building?\n",
      "Response generated for id: 67\n",
      "[2024-11-15 14:48:15,750: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 7.000000 seconds]\n",
      "Response generated for query: What makes the King Kool Lounge a comfy choice for users?\n",
      "Response generated for id: 68\n",
      "[2024-11-15 14:48:28,262: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:48:28,263: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:48:30,705: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 17.000000 seconds]\n",
      "Response generated for query: What makes the raft great for reading in the pool?\n",
      "Response generated for id: 69\n",
      "[2024-11-15 14:48:53,671: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:48:53,672: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:48:55,828: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 22.000000 seconds]\n",
      "Response generated for query: What combines relaxation and convenience in the Intex King Kool Lounge?\n",
      "Response generated for id: 70\n",
      "[2024-11-15 14:49:23,658: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:49:23,658: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:49:28,562: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 18.000000 seconds]\n",
      "Response generated for query: What makes the game easy to learn for players of different ages?\n",
      "Response generated for id: 71\n",
      "[2024-11-15 14:49:52,943: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:49:52,943: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:49:54,781: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 21.000000 seconds]\n",
      "Response generated for query: What makes the game enjoyable for players in terms of replayability?\n",
      "Response generated for id: 72\n",
      "[2024-11-15 14:50:22,352: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:50:22,354: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:50:24,006: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:50:24,007: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:50:26,200: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 49.000000 seconds]\n",
      "Response generated for query: What are the perks of organized storage for kids' game setup?\n",
      "Response generated for id: 73\n",
      "[2024-11-15 14:51:22,147: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:51:22,148: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:51:23,627: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 19.000000 seconds]\n",
      "Response generated for query: What qualities make the durable toys suitable for long-term use?\n",
      "Response generated for id: 74\n",
      "[2024-11-15 14:51:49,510: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:51:49,511: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:51:51,266: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:51:51,267: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:51:53,118: INFO: _base_client: Retrying request to /openai/v1/chat/completions in 31.000000 seconds]\n",
      "Response generated for query: What are the storage and usage considerations for Play-Doh?\n",
      "Response generated for id: 75\n",
      "[2024-11-15 14:52:32,137: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:52:32,138: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:52:34,371: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:52:34,372: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:52:35,874: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:52:35,874: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:52:37,592: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:52:37,593: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "Error invoking agent for Index: 76 - Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-70b-versatile` in organization `org_01jcrm2x5rfjqbwamj32k2jcv2` on : Limit 200000, Used 196749, Requested 5147. Please try again in 13m38.747999999s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': '', 'code': 'rate_limit_exceeded'}}\n",
      "[2024-11-15 14:52:42,170: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:52:42,171: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:52:43,594: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:52:43,595: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:52:45,480: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:52:45,480: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:52:47,819: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:52:47,820: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:52:51,516: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:52:51,518: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:52:54,555: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:52:54,556: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:53:06,407: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:53:06,408: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:53:07,859: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:53:07,860: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:53:09,346: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:53:09,347: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:53:11,226: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:53:11,227: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:53:12,931: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:53:12,932: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "Error invoking agent for Index: 77 - Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT\n",
      "Response generated for query: What are the key features of the inflatable kiddie pool designed for kids aged 3 and above?\n",
      "Response generated for id: 78\n",
      "[2024-11-15 14:53:23,605: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:53:23,606: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:53:24,826: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:53:24,827: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "[2024-11-15 14:53:26,153: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:53:26,154: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "Error invoking agent for Index: 79 - Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-70b-versatile` in organization `org_01jcrm2x5rfjqbwamj32k2jcv2` on : Limit 200000, Used 198323, Requested 5042. Please try again in 24m13.316s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': '', 'code': 'rate_limit_exceeded'}}\n",
      "[2024-11-15 14:53:29,720: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:53:29,721: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "Error invoking agent for Index: 80 - Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-70b-versatile` in organization `org_01jcrm2x5rfjqbwamj32k2jcv2` on : Limit 200000, Used 198303, Requested 2402. Please try again in 5m4.459s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': '', 'code': 'rate_limit_exceeded'}}\n",
      "Response generated for query: What is the purpose of the Magic 8 Ball toy?\n",
      "Response generated for id: 81\n",
      "[2024-11-15 14:53:43,003: INFO: SentenceTransformer: Use pytorch device_name: mps]\n",
      "[2024-11-15 14:53:43,004: INFO: SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2]\n",
      "Error invoking agent for Index: 82 - Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-70b-versatile` in organization `org_01jcrm2x5rfjqbwamj32k2jcv2` on : Limit 200000, Used 199705, Requested 931. Please try again in 4m34.515s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': '', 'code': 'rate_limit_exceeded'}}\n"
     ]
    }
   ],
   "source": [
    "for index, row in test_df.iterrows():\n",
    "    cache_key = f\"{row['file_hash']}-{row['parent_asin']}\"\n",
    "    \n",
    "    if cache_key not in vector_store_cache:\n",
    "        review_df, meta_df = load_product_data(row['parent_asin'])\n",
    "        vector_db = create_vector_store(review_df)\n",
    "        vector_db.save_local(f\"{faiss_dir}/{cache_key}\")\n",
    "        meta_df.to_csv(f\"{meta_dir}/{cache_key}.csv\", index=False)\n",
    "        vector_store_cache.append(cache_key)\n",
    "\n",
    "    retriever = faiss_dir / cache_key\n",
    "    meta_df = meta_dir / f\"{cache_key}.csv\"\n",
    "\n",
    "    config = {}\n",
    "\n",
    "    run_id = str(uuid.uuid4())\n",
    "    langfuse_handler = CallbackHandler(\n",
    "        user_id=f\"Model-Evaluation-1\",\n",
    "        session_id=f\"{cache_key}\"\n",
    "    )\n",
    "    config.update({\"callbacks\": [langfuse_handler], \"run_id\": run_id})\n",
    "\n",
    "\n",
    "    try:\n",
    "        response = agent.invoke({\n",
    "            \"question\": row['question'], \n",
    "            \"meta_data\": str(meta_df),\n",
    "            \"retriever\": str(retriever)\n",
    "        }, config=config)\n",
    "        print(f\"Response generated for query: {row['question']}\")\n",
    "        print(f\"Response generated for id: {index}\")\n",
    "        \n",
    "        test_df.at[index, 'answer'] = response['answer'].content\n",
    "        time.sleep(2)\n",
    "    except Exception as e:\n",
    "        row['answer']=''\n",
    "        print(f\"Error invoking agent for Index: {index} - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>evolution_type</th>\n",
       "      <th>file_hash</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What has been your experience with the Dirt De...</td>\n",
       "      <td>[We just retired our dirt devil after almost 2...</td>\n",
       "      <td>My experience with the Dirt Devil over the two...</td>\n",
       "      <td>simple</td>\n",
       "      <td>36a3c3df-563c-412a-b2a2-a317e1f96f3f</td>\n",
       "      <td>B000050B3H</td>\n",
       "      <td>Based on the reviews provided, I found one use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What type of game is suitable for a family gat...</td>\n",
       "      <td>[This is a fun game whether with your family o...</td>\n",
       "      <td>The game described is suitable for a family ga...</td>\n",
       "      <td>simple</td>\n",
       "      <td>5353bd53-9b26-4e21-8a59-ef55cd8a09d2</td>\n",
       "      <td>B00000IV35</td>\n",
       "      <td>Based on the context provided (none), I don't ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What type of game is mentioned as being simila...</td>\n",
       "      <td>[If you like playing Gin Rummy you’ll love thi...</td>\n",
       "      <td>The answer to given question is not present in...</td>\n",
       "      <td>simple</td>\n",
       "      <td>5353bd53-9b26-4e21-8a59-ef55cd8a09d2</td>\n",
       "      <td>B00000IV35</td>\n",
       "      <td>The game mentioned as being similar to Gin Rum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Any game recommendations for Gin Rummy fans?</td>\n",
       "      <td>[If you like playing Gin Rummy you’ll love thi...</td>\n",
       "      <td>The answer to given question is not present in...</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>5353bd53-9b26-4e21-8a59-ef55cd8a09d2</td>\n",
       "      <td>B00000IV35</td>\n",
       "      <td>Based on the product information available, I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What type of game can be played with grand-kid...</td>\n",
       "      <td>[Fun game for even or  odd number of players. ...</td>\n",
       "      <td>The game that can be played with grand-kids th...</td>\n",
       "      <td>simple</td>\n",
       "      <td>fe4ac26f-2ed9-4911-9134-77338a775a02</td>\n",
       "      <td>1933054395</td>\n",
       "      <td>Since the context is empty, I'll provide a gen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What has been your experience with the Dirt De...   \n",
       "1  What type of game is suitable for a family gat...   \n",
       "2  What type of game is mentioned as being simila...   \n",
       "3       Any game recommendations for Gin Rummy fans?   \n",
       "4  What type of game can be played with grand-kid...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [We just retired our dirt devil after almost 2...   \n",
       "1  [This is a fun game whether with your family o...   \n",
       "2  [If you like playing Gin Rummy you’ll love thi...   \n",
       "3  [If you like playing Gin Rummy you’ll love thi...   \n",
       "4  [Fun game for even or  odd number of players. ...   \n",
       "\n",
       "                                        ground_truth evolution_type  \\\n",
       "0  My experience with the Dirt Devil over the two...         simple   \n",
       "1  The game described is suitable for a family ga...         simple   \n",
       "2  The answer to given question is not present in...         simple   \n",
       "3  The answer to given question is not present in...      reasoning   \n",
       "4  The game that can be played with grand-kids th...         simple   \n",
       "\n",
       "                              file_hash parent_asin  \\\n",
       "0  36a3c3df-563c-412a-b2a2-a317e1f96f3f  B000050B3H   \n",
       "1  5353bd53-9b26-4e21-8a59-ef55cd8a09d2  B00000IV35   \n",
       "2  5353bd53-9b26-4e21-8a59-ef55cd8a09d2  B00000IV35   \n",
       "3  5353bd53-9b26-4e21-8a59-ef55cd8a09d2  B00000IV35   \n",
       "4  fe4ac26f-2ed9-4911-9134-77338a775a02  1933054395   \n",
       "\n",
       "                                              answer  \n",
       "0  Based on the reviews provided, I found one use...  \n",
       "1  Based on the context provided (none), I don't ...  \n",
       "2  The game mentioned as being similar to Gin Rum...  \n",
       "3  Based on the product information available, I ...  \n",
       "4  Since the context is empty, I'll provide a gen...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['contexts'] = test_df['contexts'].apply(lambda x: [x])\n",
    "test_dataset = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   1%|          | 2/332 [00:04<11:55,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-15 15:14:20,118: WARNING: _faithfulness: No statements were generated from the answer.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  36%|███▌      | 118/332 [00:47<01:47,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-15 15:15:02,382: WARNING: _faithfulness: No statements were generated from the answer.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  43%|████▎     | 144/332 [00:57<00:55,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-15 15:15:12,742: WARNING: _faithfulness: No statements were generated from the answer.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  46%|████▌     | 152/332 [01:00<01:01,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-15 15:15:16,204: WARNING: _faithfulness: No statements were generated from the answer.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  52%|█████▏    | 171/332 [01:05<00:54,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-15 15:15:20,431: WARNING: _faithfulness: No statements were generated from the answer.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  82%|████████▏ | 271/332 [01:38<00:10,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-15 15:15:53,816: WARNING: _faithfulness: No statements were generated from the answer.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 332/332 [02:21<00:00,  2.35it/s]\n"
     ]
    }
   ],
   "source": [
    "result = evaluate(\n",
    "    test_dataset,\n",
    "    metrics=[\n",
    "        context_precision,\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_recall,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>evolution_type</th>\n",
       "      <th>file_hash</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>answer</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What has been your experience with the Dirt De...</td>\n",
       "      <td>[We just retired our dirt devil after almost 2...</td>\n",
       "      <td>My experience with the Dirt Devil over the two...</td>\n",
       "      <td>simple</td>\n",
       "      <td>36a3c3df-563c-412a-b2a2-a317e1f96f3f</td>\n",
       "      <td>B000050B3H</td>\n",
       "      <td>Based on the reviews provided, I found one use...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What type of game is suitable for a family gat...</td>\n",
       "      <td>[This is a fun game whether with your family o...</td>\n",
       "      <td>The game described is suitable for a family ga...</td>\n",
       "      <td>simple</td>\n",
       "      <td>5353bd53-9b26-4e21-8a59-ef55cd8a09d2</td>\n",
       "      <td>B00000IV35</td>\n",
       "      <td>Based on the context provided (none), I don't ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What type of game is mentioned as being simila...</td>\n",
       "      <td>[If you like playing Gin Rummy you’ll love thi...</td>\n",
       "      <td>The answer to given question is not present in...</td>\n",
       "      <td>simple</td>\n",
       "      <td>5353bd53-9b26-4e21-8a59-ef55cd8a09d2</td>\n",
       "      <td>B00000IV35</td>\n",
       "      <td>The game mentioned as being similar to Gin Rum...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.992131</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Any game recommendations for Gin Rummy fans?</td>\n",
       "      <td>[If you like playing Gin Rummy you’ll love thi...</td>\n",
       "      <td>The answer to given question is not present in...</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>5353bd53-9b26-4e21-8a59-ef55cd8a09d2</td>\n",
       "      <td>B00000IV35</td>\n",
       "      <td>Based on the product information available, I ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What type of game can be played with grand-kid...</td>\n",
       "      <td>[Fun game for even or  odd number of players. ...</td>\n",
       "      <td>The game that can be played with grand-kids th...</td>\n",
       "      <td>simple</td>\n",
       "      <td>fe4ac26f-2ed9-4911-9134-77338a775a02</td>\n",
       "      <td>1933054395</td>\n",
       "      <td>Since the context is empty, I'll provide a gen...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What has been your experience with the Dirt De...   \n",
       "1  What type of game is suitable for a family gat...   \n",
       "2  What type of game is mentioned as being simila...   \n",
       "3       Any game recommendations for Gin Rummy fans?   \n",
       "4  What type of game can be played with grand-kid...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [We just retired our dirt devil after almost 2...   \n",
       "1  [This is a fun game whether with your family o...   \n",
       "2  [If you like playing Gin Rummy you’ll love thi...   \n",
       "3  [If you like playing Gin Rummy you’ll love thi...   \n",
       "4  [Fun game for even or  odd number of players. ...   \n",
       "\n",
       "                                        ground_truth evolution_type  \\\n",
       "0  My experience with the Dirt Devil over the two...         simple   \n",
       "1  The game described is suitable for a family ga...         simple   \n",
       "2  The answer to given question is not present in...         simple   \n",
       "3  The answer to given question is not present in...      reasoning   \n",
       "4  The game that can be played with grand-kids th...         simple   \n",
       "\n",
       "                              file_hash parent_asin  \\\n",
       "0  36a3c3df-563c-412a-b2a2-a317e1f96f3f  B000050B3H   \n",
       "1  5353bd53-9b26-4e21-8a59-ef55cd8a09d2  B00000IV35   \n",
       "2  5353bd53-9b26-4e21-8a59-ef55cd8a09d2  B00000IV35   \n",
       "3  5353bd53-9b26-4e21-8a59-ef55cd8a09d2  B00000IV35   \n",
       "4  fe4ac26f-2ed9-4911-9134-77338a775a02  1933054395   \n",
       "\n",
       "                                              answer  context_precision  \\\n",
       "0  Based on the reviews provided, I found one use...                1.0   \n",
       "1  Based on the context provided (none), I don't ...                1.0   \n",
       "2  The game mentioned as being similar to Gin Rum...                0.0   \n",
       "3  Based on the product information available, I ...                0.0   \n",
       "4  Since the context is empty, I'll provide a gen...                1.0   \n",
       "\n",
       "   faithfulness  answer_relevancy  context_recall  \n",
       "0      0.666667          0.000000             1.0  \n",
       "1      0.000000          0.000000             1.0  \n",
       "2      0.333333          0.992131             0.0  \n",
       "3      0.166667          0.000000             0.0  \n",
       "4      0.052632          0.000000             1.0  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = result.to_pandas()\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        context_precision  faithfulness  answer_relevancy  context_recall\n",
      "min              0.000000      0.000000          0.000000        0.000000\n",
      "max              1.000000      1.000000          1.000000        1.000000\n",
      "median           1.000000      0.333333          0.936512        1.000000\n",
      "mean             0.746988      0.393843          0.689093        0.808434\n"
     ]
    }
   ],
   "source": [
    "# Assuming results_df is your DataFrame\n",
    "columns_of_interest = ['context_precision', 'faithfulness', 'answer_relevancy', 'context_recall']\n",
    "\n",
    "# Calculate the min, max, median, and mean for each column\n",
    "statistics = results_df[columns_of_interest].agg(['min', 'max', 'median', 'mean'])\n",
    "print(statistics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_precision</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>evolution_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>multi_context</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.399912</td>\n",
       "      <td>0.951992</td>\n",
       "      <td>0.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reasoning</th>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.414901</td>\n",
       "      <td>0.752246</td>\n",
       "      <td>0.826667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple</th>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.384584</td>\n",
       "      <td>0.646047</td>\n",
       "      <td>0.802424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                context_precision  faithfulness  answer_relevancy  \\\n",
       "evolution_type                                                      \n",
       "multi_context            0.666667      0.399912          0.951992   \n",
       "reasoning                0.720000      0.414901          0.752246   \n",
       "simple                   0.763636      0.384584          0.646047   \n",
       "\n",
       "                context_recall  \n",
       "evolution_type                  \n",
       "multi_context         0.766667  \n",
       "reasoning             0.826667  \n",
       "simple                0.802424  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_means = results_df.groupby('evolution_type')[columns_of_interest].mean()\n",
    "grouped_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_parquet(f'{EVAL_RESULTS_DIR}/version0.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_parquet(f'{EVAL_RESULTS_DIR}/version0-results.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dict = grouped_means.to_dict()\n",
    "\n",
    "# Save the dictionary to a JSON file\n",
    "with open(f\"{EVAL_PARENT_DIR}/metrics/version0-metrics.json\", \"w\") as json_file:\n",
    "    json.dump(metrics_dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log to MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.models.set_model(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"eCom-dev5/eCom-Chatbot\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"eCom-dev5/eCom-Chatbot\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-15 16:01:51,425: INFO: helpers: Initialized MLflow to track repo \"eCom-dev5/eCom-Chatbot\"]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository eCom-dev5/eCom-Chatbot initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository eCom-dev5/eCom-Chatbot initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-15 16:01:51,426: INFO: helpers: Repository eCom-dev5/eCom-Chatbot initialized!]\n",
      "https\n",
      "[2024-11-15 16:01:51,452: WARNING: connectionpool: Retrying (Retry(total=4, connect=5, read=4, redirect=5, status=5)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /eCom-dev5/eCom-Chatbot.mlflow/api/2.0/mlflow/runs/create]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/15 16:01:51 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Successfully registered model 'verta-gpt40m-llama3.18b-llama3.170b-version0'.\n",
      "2024/11/15 16:01:54 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: verta-gpt40m-llama3.18b-llama3.170b-version0, version 1\n",
      "Created version '1' of model 'verta-gpt40m-llama3.18b-llama3.170b-version0'.\n",
      "2024/11/15 16:02:07 INFO mlflow.tracking._tracking_service.client: 🏃 View run skittish-midge-312 at: https://dagshub.com/eCom-dev5/eCom-Chatbot.mlflow/#/experiments/0/runs/8e1e8126ed744d77bced6ee8faf2fdc2.\n",
      "2024/11/15 16:02:07 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: https://dagshub.com/eCom-dev5/eCom-Chatbot.mlflow/#/experiments/0.\n"
     ]
    }
   ],
   "source": [
    "dagshub.init(repo_owner='eCom-dev5', repo_name='eCom-Chatbot', mlflow=True)\n",
    "mlflow.set_registry_uri(\"https://dagshub.com/eCom-dev5/eCom-Chatbot.mlflow\")\n",
    "tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "\n",
    "with mlflow.start_run():\n",
    "  if tracking_url_type_store != \"file\":\n",
    "    mlflow.langchain.log_model(\n",
    "      lc_model=\"src/graph.py\", # Path to our model Python file\n",
    "      artifact_path=\"version0\",\n",
    "      pip_requirements=\"requirements.txt\",\n",
    "      registered_model_name=\"verta-gpt40m-llama3.18b-llama3.170b-version0\"\n",
    "    )\n",
    "  else:\n",
    "    mlflow.langchain.log_model(\n",
    "      lc_model=\"src/graph.py\", # Path to our model Python file\n",
    "      artifact_path=\"version0\",\n",
    "      pip_requirements=\"requirements.txt\",\n",
    "      registered_model_name=\"verta-gpt40m-llama3.18b-llama3.170b-version0\"\n",
    "    )\n",
    "\n",
    "  mlflow.log_param(\n",
    "    'Supervisor Prompt',\n",
    "    ''''\n",
    "    You are an efficient supervisor responsible for overseeing a conversation between the following agents: {members}. \n",
    "\n",
    "    If you got response from the Agent (response given below as \"Generated Answer from the Agents:\"), respond with 'FINISH' to move on to next step. \n",
    "    \n",
    "    Based on the user's request, decide which agent should respond next. Each agent will complete a task and return their result. \n",
    "    \n",
    "    There are two agents working alongside you:\n",
    "        - Metadata: This agent has all metadata information about that product. \n",
    "        - Review-Vectorstore: This is a FAISS Vectorstore db containing documents related to all the user reviews for that product.\n",
    "    \n",
    "    If you got unsatisfied response from the Agents (Agent Throwing Errors like: \"Metadata: Unable to generate result\") ONLY THEN Call an Agent a **MAXIMUM of TWO TIMES** before responding with 'FINISH'.\n",
    "    Once sufficient information is obtained from the Agents, respond with 'FINISH', after which Alpha, the final assistant, will provide the concluding guidance to the user.\n",
    "    If the query is generic (Hello, How are you, etc) then route it to Alpha and respond with 'FINISH.' \n",
    "\n",
    "    If you got satisfactory response from the Agent (response given above), respond with 'FINISH' to move on to next step. \n",
    "    '''\n",
    "  )\n",
    "\n",
    "  mlflow.log_param(\n",
    "    'Final Node Prompt',\n",
    "    f'''\n",
    "    You are Alpha, a highly knowledgeable and efficient chatbot assistant designed to help users with questions related to products.\n",
    "    Your primary role is to assist users by providing concise, accurate, and insightful responses based on the product information and reviews available to you.\n",
    "    If you don’t have the necessary information to answer the question, simply say that you don’t know.\n",
    "\n",
    "    There are two agents working alongside you:\n",
    "    - Metadata: This agent provides answers related to a product. It has all the information about that product.\n",
    "    - Review-Vectorstore: This is a FAISS Vectorstore db containing documents related to all the user reviews for one product.\n",
    "    \n",
    "    When a User (Shopper) comes to you for help, the question might have first been routed through either the Metadata or the Review-Vectorstore. \n",
    "\n",
    "    Your primary objective is to offer clear, concise, and helpful advice to the teacher, ensuring that they receive the most accurate and useful information to support their shopping needs.\n",
    "\n",
    "    Instructions:\n",
    "    - Analyze the product information and/or reviews provided.\n",
    "    - Provide brief, clear, and helpful answers to user queries about the product.\n",
    "    - Focus on delivering concise and actionable insights to help users make informed decisions.\n",
    "\n",
    "    The responses from those agents are available to you, and if their answers were incomplete or unsatisfactory, you will find this reflected in the context field. \n",
    "    Your job is to analyze their responses, determine if they are adequate, and provide additional guidance or clarification where needed.\n",
    "    Below is the context from one of the agents:\n",
    "    '''\n",
    "  )\n",
    "\n",
    "  mlflow.log_param(\n",
    "    'Follow-up Node Prompt',\n",
    "    '''\n",
    "    Given the following:\n",
    "    User Question: {question}\n",
    "    Answer: {answer}\n",
    "    Context: {context}\n",
    "    Please generate three possible follow-up questions that the user might ask, each on a new line, without any numbering or bullet points. Do not include any explanations—just list the follow-up questions.\n",
    "    Format them like this:\n",
    "    question1\\nquestion2\\nquestion3\n",
    "    '''\n",
    "  )\n",
    "  \n",
    "  for evolution_type, row in grouped_means.iterrows():\n",
    "    for metric_name, metric_value in row.items():\n",
    "        # Construct a unique metric name with the evolution type\n",
    "        metric_name_with_type = f\"{evolution_type}_{metric_name}\"\n",
    "        # Log the metric\n",
    "        mlflow.log_metric(metric_name_with_type, metric_value)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
